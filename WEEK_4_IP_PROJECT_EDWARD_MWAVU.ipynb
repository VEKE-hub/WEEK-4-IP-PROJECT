{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WEEK 4 IP PROJECT EDWARD MWAVU",
      "provenance": [],
      "authorship_tag": "ABX9TyNuZpBSv4+Hpf71VZ7UJ8nb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VEKE-hub/WEEK-4-IP-PROJECT/blob/main/WEEK_4_IP_PROJECT_EDWARD_MWAVU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDCr87C2lOPE"
      },
      "source": [
        "Python Data cleaning and analysis-electric car-sharing service company\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dAr_nm6lXWi"
      },
      "source": [
        "1.0 Importing our libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD7jkHCBlcPI"
      },
      "source": [
        "# Importing the libraries we will need \n",
        "\n",
        "# Importing the pandas library\n",
        "# \n",
        "import pandas as pd\n",
        "\n",
        "# Importing the numpy library\n",
        "#\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwY2q7TaoYUG"
      },
      "source": [
        "1.1 Reading the Dataset from our CSV file\n",
        "\n",
        "You can get the data and the dataset description for this Independent project here [http://bit.ly/autolib_dataset] and here respectively \n",
        "\n",
        " [Link].  The dataset contains data collected for a period of 9 days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoiCq38opDt7"
      },
      "source": [
        "# Let's  read the data from the csv file and create the dataframe to be used\n",
        "# \n",
        "with open('Autolib_dataset.csv')as f;\n",
        "pdf = pd.read_csv(f, index_col=else, encoding= 'utf=8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNM7XqDLumHM"
      },
      "source": [
        "1.2 Previewing Our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulyJ0Dxius1Y"
      },
      "source": [
        "# Let's preview the first 5 rows of our data\n",
        "#\n",
        "pdf.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMUVcGXevfcn"
      },
      "source": [
        "1.3 Accessing information about our Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgRj1ak0wEEP"
      },
      "source": [
        "#Getting to know more about the dataset by accessing its information\n",
        "#\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBNHurynwsAO"
      },
      "source": [
        "1.4 Cleaning our Datasets\n",
        "\n",
        "Let us perform data cleaning procedures below providing a documentation for our actions and reasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqGsvCZHxlhY"
      },
      "source": [
        "1.4.1 Validity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hf8ygKwyIoe"
      },
      "source": [
        "# Irrelevant Data Observation\n",
        "# Data Cleaning Action; Dropping Scheduled at attribute\n",
        "# Explanation: We don't need it during Analysis since no question requires that column.\n",
        "#\n",
        "pd.drop(columns = 'Scheduled at', inplace = True)\n",
        "pdf.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpRi38hwzl6i"
      },
      "source": [
        "1.4.2 Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0JSPCA10dqN"
      },
      "source": [
        "# If record & cross-datasets errors\n",
        "# These errors result from having two or more valuesin same row or accross\n",
        "# datasets that contradict with each other\n",
        "# example if we have dataset about cars and there is only Bluecar Counter\n",
        "# The total number of cars should be equal to the total number of Bluecar counter\n",
        "# Using the dataset given below determine and fix errors where total number of cars is not sum of\n",
        "# total Bluecar counter\n",
        "# dataset url =  [http://bit.ly/autolib_dataset]\n",
        "#\n",
        "df = pd.read_csv(' [http://bit.ly/autolib_dataset]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUAW21Ec4Z4H"
      },
      "source": [
        "1.4.3 Completeness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PfOHb3-4gFP"
      },
      "source": [
        "#DataCleaning & Actions\n",
        "#Explanation: to ensure the error is removed and sum os equal\n",
        "#\n",
        "df.carsum() = Bluecar counter sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLA6Pu2M5KuJ"
      },
      "source": [
        "1.4.4 Uniformity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9w4XXBD6UKg"
      },
      "source": [
        "# Data cleaning & Action; Renewing column to include the %sign\n",
        "# Explanation' Shows that the data is still in percentages\n",
        "#\n",
        "columns = ['Address','Cars%','Bluecar Counter%','Utilib Counter%','Utilib 1.4 Counter%',]\n",
        "df.columns = columns\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH48Qd5i8dDN"
      },
      "source": [
        "1.5 Exporting the cleaned datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpprBZ7Y8m7r"
      },
      "source": [
        "# Let's export our dataframe into a csv file as shown\n",
        "# In the example given in the following line\n",
        "# dataframe.to_csv('cleaned.csv')\n",
        "# In the above case dataframe is the dataframe which would like to export.\n",
        "# We use to_csv function to create a csv file with the name cleaned\n",
        "# and export it\n",
        "#\n",
        "df.to_csv('cleaned.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}